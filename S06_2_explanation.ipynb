{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculations for the word: 'cat'\n",
      "\n",
      "Document 1:\n",
      "Occurrences of 'cat' in document: 1 out of 6 total words\n",
      "TF (Term Frequency): 1/6 = 0.1667\n",
      "Occurrences of 'cat' in corpus: 2 out of 4 documents\n",
      "IDF (Inverse Document Frequency): log(4 / (1 + 2)) + 1 = 1.2877\n",
      "TF-IDF: 0.1667 * 1.2877 = 0.2146\n",
      "\n",
      "Document 2:\n",
      "Occurrences of 'cat' in document: 0 out of 6 total words\n",
      "TF (Term Frequency): 0/6 = 0.0000\n",
      "Occurrences of 'cat' in corpus: 2 out of 4 documents\n",
      "IDF (Inverse Document Frequency): log(4 / (1 + 2)) + 1 = 1.2877\n",
      "TF-IDF: 0.0000 * 1.2877 = 0.0000\n",
      "\n",
      "Document 3:\n",
      "Occurrences of 'cat' in document: 0 out of 6 total words\n",
      "TF (Term Frequency): 0/6 = 0.0000\n",
      "Occurrences of 'cat' in corpus: 2 out of 4 documents\n",
      "IDF (Inverse Document Frequency): log(4 / (1 + 2)) + 1 = 1.2877\n",
      "TF-IDF: 0.0000 * 1.2877 = 0.0000\n",
      "\n",
      "Document 4:\n",
      "Occurrences of 'cat' in document: 1 out of 7 total words\n",
      "TF (Term Frequency): 1/7 = 0.1429\n",
      "Occurrences of 'cat' in corpus: 2 out of 4 documents\n",
      "IDF (Inverse Document Frequency): log(4 / (1 + 2)) + 1 = 1.2877\n",
      "TF-IDF: 0.1429 * 1.2877 = 0.1840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Step 1: Define a small corpus (set of documents)\n",
    "corpus = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"The dog sat on the log.\",\n",
    "    \"Dogs and cats are great pets.\",\n",
    "    \"I love my pet cat and dog.\"\n",
    "]\n",
    "\n",
    "# Step 2: Preprocess the text (tokenization and lowercase)\n",
    "def tokenize(text):\n",
    "    return text.lower().replace('.', '').split()\n",
    "\n",
    "tokenized_corpus = [tokenize(doc) for doc in corpus]\n",
    "\n",
    "# Step 3: Calculate Term Frequency (TF)\n",
    "def compute_tf(document):\n",
    "    tf_scores = {}\n",
    "    total_terms = len(document)\n",
    "    term_counts = Counter(document)\n",
    "    for term, count in term_counts.items():\n",
    "        tf_scores[term] = count / total_terms\n",
    "    return tf_scores, term_counts, total_terms\n",
    "\n",
    "# Step 4: Calculate Inverse Document Frequency (IDF)\n",
    "def compute_idf(corpus):\n",
    "    idf_scores = {}\n",
    "    total_documents = len(corpus)\n",
    "    all_terms = set(term for document in corpus for term in document)\n",
    "    for term in all_terms:\n",
    "        containing_docs = sum(1 for document in corpus if term in document)\n",
    "        idf_scores[term] = math.log(total_documents / (1 + containing_docs)) + 1  # Smoothing\n",
    "    return idf_scores\n",
    "\n",
    "# Step 5: Calculate TF-IDF for each document\n",
    "def compute_tf_idf(corpus):\n",
    "    idf_scores = compute_idf(corpus)\n",
    "    tf_idf_corpus = []\n",
    "    for document in corpus:\n",
    "        tf_scores, term_counts, total_terms = compute_tf(document)\n",
    "        tf_idf_scores = {term: tf_scores.get(term, 0) * idf_scores[term] for term in idf_scores}\n",
    "        tf_idf_corpus.append((tf_idf_scores, term_counts, total_terms))\n",
    "    return tf_idf_corpus, idf_scores\n",
    "\n",
    "# Calculate TF-IDF and IDF\n",
    "tf_idf_corpus, idf_scores = compute_tf_idf(tokenized_corpus)\n",
    "\n",
    "# Step 6: Display calculations for a specific word\n",
    "word = \"cat\"  # You can change this to any word of interest\n",
    "\n",
    "print(f\"Calculations for the word: '{word}'\\n\")\n",
    "for i, (doc_scores, term_counts, total_terms) in enumerate(tf_idf_corpus):\n",
    "    tf = term_counts.get(word, 0) / total_terms if word in term_counts else 0\n",
    "    idf = idf_scores.get(word, 0)\n",
    "    tf_idf = tf * idf\n",
    "    doc_occurrences = term_counts.get(word, 0)\n",
    "    total_docs_with_word = sum(1 for document in tokenized_corpus if word in document)\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(f\"Occurrences of '{word}' in document: {doc_occurrences} out of {total_terms} total words\")\n",
    "    print(f\"TF (Term Frequency): {doc_occurrences}/{total_terms} = {tf:.4f}\")\n",
    "    print(f\"Occurrences of '{word}' in corpus: {total_docs_with_word} out of {len(corpus)} documents\")\n",
    "    print(f\"IDF (Inverse Document Frequency): log({len(corpus)} / (1 + {total_docs_with_word})) + 1 = {idf:.4f}\")\n",
    "    print(f\"TF-IDF: {tf:.4f} * {idf:.4f} = {tf_idf:.4f}\\n\")\n",
    "\n",
    "# Explanation:\n",
    "# - TF (Term Frequency): How often a word appears in a document divided by total terms.\n",
    "# - IDF (Inverse Document Frequency): Measures how unique a word is across all documents.\n",
    "# - TF-IDF: Higher scores for words that are frequent in one document but rare across the corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regex Matching Evaluation:\n",
      "True Positives (TP): 5\n",
      "True Negatives (TN): 0\n",
      "False Positives (FP): 0\n",
      "False Negatives (FN): 0\n",
      "\n",
      "Performance Metrics:\n",
      "Precision: 5 / (5 + 0) = 1.0000\n",
      "Recall: 5 / (5 + 0) = 1.0000\n",
      "F1 Score: 2 * (1.0000 * 1.0000) / (1.0000 + 1.0000) = 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Step 1: Define a small corpus with regex pattern matching examples\n",
    "corpus = [\n",
    "    \"My email is john.doe@example.com and my backup is doe.john@work.org.\",\n",
    "    \"Reach out at contact@company.net for inquiries.\",\n",
    "    \"Invalid emails like user@@domain..com should not be captured.\",\n",
    "    \"Another valid email: support@service.co.uk and one more: hello@domain.io.\"\n",
    "]\n",
    "\n",
    "# Step 2: Preprocess the text (tokenization and lowercase)\n",
    "def tokenize(text):\n",
    "    return text.lower().replace('.', '').split()\n",
    "\n",
    "tokenized_corpus = [tokenize(doc) for doc in corpus]\n",
    "\n",
    "# Step 3: Define regex pattern for email capture\n",
    "email_pattern = r'\\b[\\w.-]+@[\\w.-]+\\.[a-zA-Z]{2,}\\b'\n",
    "\n",
    "# Initialize counters for TP, TN, FP, FN\n",
    "TP = 0  # Correctly captured valid emails\n",
    "TN = 0  # Correctly not captured invalid parts\n",
    "FP = 0  # Incorrectly captured invalid parts\n",
    "FN = 0  # Missed valid emails\n",
    "\n",
    "# Define actual valid emails manually for this example\n",
    "valid_emails = {\n",
    "    \"john.doe@example.com\", \"doe.john@work.org\",\n",
    "    \"contact@company.net\", \"support@service.co.uk\", \"hello@domain.io\"\n",
    "}\n",
    "\n",
    "# Step 4: Perform regex matching and classification\n",
    "for i, text in enumerate(corpus):\n",
    "    matches = set(re.findall(email_pattern, text))\n",
    "    expected = set(email for email in valid_emails if email in text)\n",
    "    false_matches = matches - expected  # Captured but invalid\n",
    "    missed_matches = expected - matches  # Valid but not captured\n",
    "    correct_matches = matches & expected  # Correctly captured valid emails\n",
    "\n",
    "    TP += len(correct_matches)\n",
    "    FP += len(false_matches)\n",
    "    FN += len(missed_matches)\n",
    "    TN += len(expected) - len(correct_matches)\n",
    "\n",
    "# Step 5: Print the confusion matrix counts\n",
    "print(\"Regex Matching Evaluation:\")\n",
    "print(f\"True Positives (TP): {TP}\")\n",
    "print(f\"True Negatives (TN): {TN}\")\n",
    "print(f\"False Positives (FP): {FP}\")\n",
    "print(f\"False Negatives (FN): {FN}\\n\")\n",
    "\n",
    "# Step 6: Calculate Precision, Recall, and F1 Score\n",
    "precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "# Step 7: Print calculated metrics with explanations\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"Precision: {TP} / ({TP} + {FP}) = {precision:.4f}\")\n",
    "print(f\"Recall: {TP} / ({TP} + {FN}) = {recall:.4f}\")\n",
    "print(f\"F1 Score: 2 * ({precision:.4f} * {recall:.4f}) / ({precision:.4f} + {recall:.4f}) = {f1_score:.4f}\\n\")\n",
    "\n",
    "# Explanation:\n",
    "# - TP: Correctly captured valid emails by regex.\n",
    "# - TN: Non-email text correctly ignored by regex.\n",
    "# - FP: Incorrect text captured as emails by regex.\n",
    "# - FN: Valid emails not captured by regex.\n",
    "#\n",
    "# - Precision: Measures accuracy of captured emails.\n",
    "# - Recall: Measures ability to capture all valid emails.\n",
    "# - F1 Score: Balances precision and recall performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
